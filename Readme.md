ğŸŸ¦ Mini Project: S3 Event Trigger â†’ Lambda â†’ DynamoDB 
=
ğŸ¯ Objective
=
 
 Build a fully serverless, event-driven data pipeline on AWS that automatically responds to file uploads in an S3 bucket by triggering a Lambda function, which extracts and stores relevant file metadata into a DynamoDB table for logging, tracking, or further processing â€” all without managing any servers.
## ğŸ§± Architecture Overview

### ğŸ“Œ Flow:

1. **User uploads a file** â†’ S3 Bucket  
2. **S3 Event Notification** â†’ Triggers Lambda Function  
3. **Lambda Function** â†’ Extracts metadata and writes to DynamoDB  

---

### ğŸ–¼ï¸ Diagram:


<img width="1115" height="416" alt="image" src="https://github.com/user-attachments/assets/7bf56833-e04e-4210-88aa-f23a2c135a2b" />

ğŸ¯Benefits of This Architecture 
=
â€¢ Serverless â€“ no servers to manage.

â€¢ Event-driven â€“ reacts in real time to file uploads.

â€¢ Scalable â€“ DynamoDB scales automatically.

â€¢ Extensible â€“ you can add file processing logic in Lambda (e.g., virus scan, metadata 
extraction). 


Prerequisites 
=
â€¢ AWS account with IAM permissions to create S3, Lambda, and DynamoDB resources.

â€¢ Basic knowledge of Python and AWS Lambda. 

